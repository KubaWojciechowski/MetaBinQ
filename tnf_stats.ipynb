{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import seaborn as sns\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "#%matplotlib inline\n",
    "#%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nucl_lists():\n",
    "    \"\"\"\n",
    "    Generate lists of possible nucleotides\n",
    "    \n",
    "    Outputs:\n",
    "    di_list - list of possible dinuclotides\n",
    "    tri_list - list of possible trinuclotides\n",
    "    tetra_list - list of possible tetranuclotides\n",
    "    \"\"\"\n",
    "    \n",
    "    nucl = [\"A\",\"T\",\"C\",\"G\"]\n",
    "    di_list = [i+j for i in nucl for j in nucl]\n",
    "    tri_list = [i+j for i in di_list for j in nucl]\n",
    "    tetra_list = [i+j for i in tri_list for j in nucl]\n",
    "\n",
    "    return (di_list, tri_list, tetra_list)\n",
    "  \n",
    "    \n",
    "def rev_comp(string):\n",
    "    \"\"\"\n",
    "    Return reverse complement of DNA strand\n",
    "    \n",
    "    Input - sequence\n",
    "    \n",
    "    Output - reverse complement\n",
    "    \"\"\"\n",
    "    \n",
    "    complementary = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'} \n",
    "    comp = ''\n",
    "    for i in string:\n",
    "        comp += complementary[i]\n",
    "\n",
    "    return comp[::-1]\n",
    "\n",
    "    \n",
    "def count_occurrences(subsequence, sequence):\n",
    "    \"\"\"\n",
    "    Count occurrences of substring in a string\n",
    "    (including overlaping substrings)\n",
    "    \n",
    "    Inputs:\n",
    "    sequence - sequence\n",
    "    subsequence - subsequence to be found in sequence\n",
    "    \n",
    "    Output: number of occurrences of subsequence in sequence\n",
    "    \"\"\"\n",
    "    number_of_occurrences = 0\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i:i+len(subsequence)] == subsequence:\n",
    "            number_of_occurrences += 1\n",
    "            \n",
    "    return number_of_occurrences\n",
    "\n",
    "\n",
    "def get_frequencies(sequence):\n",
    "    \"\"\"\n",
    "    Count occurrences of oligonuclotides in sequence\n",
    "    \n",
    "    Input - sequence\n",
    "    \n",
    "    Output - array of tetranuclotides counts\n",
    "    \"\"\"\n",
    "    encoding = {'A':0, 'T':1, 'C':2, 'G':3}\n",
    "    \n",
    "    seq = np.zeros(4)\n",
    "    tetra_freq = np.ones(256)\n",
    "    \n",
    "    non_nucl = 0\n",
    "    \n",
    "    n = 1\n",
    "    for i in sequence:\n",
    "\n",
    "        if i in ['A','T','C','G']:\n",
    "            seq[0] = seq[1]\n",
    "            seq[1] = seq[2]\n",
    "            seq[2] = seq[3]\n",
    "            seq = seq*4\n",
    "            seq[3] = encoding[i]\n",
    "\n",
    "            if n > 3:\n",
    "                tetra_freq[int(seq.sum())] += 1\n",
    "            n +=1\n",
    "            \n",
    "        else:\n",
    "            non_nucl += 1 \n",
    "    \n",
    "    if non_nucl > 0:\n",
    "        print(\"Warning: %i characters other than A T C G found\" % non_nucl)\n",
    "    return(tetra_freq)\n",
    "\n",
    "\n",
    "def get_23(tetra_list, tetra_freq, tri_list, di_list):\n",
    "    \"\"\"\n",
    "    Extract tri and di nucleotides frequencies \n",
    "    from tetranucleotides frequencies \n",
    "    \n",
    "    imputs:\n",
    "    di_list - list of possible dinuclotides\n",
    "    tri_list - list of possible trinuclotides\n",
    "    tetra_list - list of possible tetranuclotides\n",
    "    tetra_freq - array of tetranuclotides counts\n",
    "    \n",
    "    Outputs:\n",
    "    tri_nucl - dictionary of trinuclotides frequency\n",
    "    di_nucl - dictionary of dinuclotides frequency\n",
    "    \"\"\"\n",
    "    #Calculate 3 and 2-mers based on 4-mers\n",
    "    di_nucl = {di_list[i]:0 for i in range(len(di_list))}\n",
    "    tri_nucl = {tri_list[i]:0 for i in range(len(tri_list))}\n",
    "    \n",
    "    for i in range(len(tetra_list)):\n",
    "        tri_nucl[tetra_list[i][0:3]] += tetra_freq[i]\n",
    "    \n",
    "    for i in tri_nucl:\n",
    "        di_nucl[i[0:2]] += tri_nucl[i]\n",
    "\n",
    "    return(tri_nucl, di_nucl)\n",
    "\n",
    "\n",
    "def rev_comp_freq(oligo_list, oligo_freq):\n",
    "    \"\"\"\n",
    "    Calculate frequencies of oligonuclotides from the complementary strand\n",
    "    \n",
    "    Inputs:\n",
    "    oligo_list - list of oligonuclotides\n",
    "    oligo_freq - list of oligonuclotides counts\n",
    "    \n",
    "    Output - updated frequencies\n",
    "    \"\"\"\n",
    "    \n",
    "    r_dir = {oligo_list[i]:oligo_freq[i] for i in range(len(oligo_list))}\n",
    "    \n",
    "    for i in range(len(oligo_list)):\n",
    "        oligo_freq[i] += r_dir[rev_comp(oligo_list[i])]\n",
    "    \n",
    "    return oligo_freq\n",
    "\n",
    "\n",
    "def exp_tnf(tetra_list, tri_nucl, di_nucl):\n",
    "    \"\"\"\n",
    "    Calculate expected tetranucleotide frequency\n",
    "    \n",
    "    Inputs:\n",
    "    tetra_list - list of tetranuclotides\n",
    "    tri_nucl - dictionary of trinuclotides frequency\n",
    "    di_nucl - dictionary of dinuclotides frequency\n",
    "    \n",
    "    Output: expected tetranuclotide frequency\n",
    "    \"\"\"\n",
    "    \n",
    "    expected_tnf = np.zeros(len(tetra_list))\n",
    "    for i in range(len(tetra_list)):\n",
    "        tn = tetra_list[i]\n",
    "        expected_tnf[i] = (tri_nucl[tn[0:3]]*tri_nucl[tn[1:4]])/di_nucl[tn[1:3]]\n",
    "            \n",
    "    return expected_tnf\n",
    "\n",
    "\n",
    "def app_variance(expected_tnf, tetra_list, tri_nucl, di_nucl):\n",
    "    \"\"\"\n",
    "    Approximated variance of tetranuclotide frequency\n",
    "    \n",
    "    Inputs:\n",
    "    expected_tnf - expected tetranuclotide frequency\n",
    "    tetra_list - list of tetranuclotides\n",
    "    tri_nucl - dictionary of trinuclotides frequency\n",
    "    di_nucl - dictionary of dinuclotides frequency\n",
    "    \n",
    "    Output - approximated variance of tetranuclotide frequency\n",
    "    \"\"\"\n",
    "    \n",
    "    app_var = np.zeros(len(tetra_list))\n",
    "    for i in range(len(tetra_list)):\n",
    "        tn = tetra_list[i]\n",
    "        n23 = di_nucl[tn[1:3]]\n",
    "        n123 = tri_nucl[tn[0:3]]\n",
    "        n234 = tri_nucl[tn[1:4]]\n",
    "        app_var[i] = expected_tnf[i] * (((n23-n123)*(n23-n234))/(n23*n23))\n",
    "            \n",
    "    return app_var\n",
    "\n",
    "\n",
    "def tnf_z_score(tetra_freq, expected_tnf, app_var):\n",
    "    \"\"\"\n",
    "    Calculate tetranuclotide z-score\n",
    "    \n",
    "    Inputs:\n",
    "    tetra_freq - observed tetranuclotide frequency\n",
    "    expected_tnf - expected tetranuclotide frequency\n",
    "    app_var - approximated variance of tetranuclotide frequency\n",
    "    \n",
    "    Output - tetranuclotide z-score\n",
    "    \"\"\"\n",
    "    \n",
    "    z_scores = (tetra_freq-expected_tnf)/np.sqrt(app_var)\n",
    "    return z_scores\n",
    "\n",
    "\n",
    "def get_z_scores(sequence, di_list, tri_list, tetra_list):\n",
    "    \"\"\"\n",
    "    Calculate z-scores from sequence\n",
    "    \n",
    "    Inputs:\n",
    "    sequence - DNA sequence\n",
    "    di_list - list of possible dinuclotides\n",
    "    tri_list - list of possible trinuclotides\n",
    "    tetra_list - list of possible tetranuclotides\n",
    "    \n",
    "    Output - np array of z-scores\n",
    "    \"\"\"\n",
    "    \n",
    "    tetra_freq = get_frequencies(sequence)\n",
    "    tetra_freq = rev_comp_freq(tetra_list, tetra_freq)\n",
    "    tri_nucl, di_nucl = get_23(tetra_list, tetra_freq, tri_list, di_list)\n",
    "    \n",
    "    expected_tnf = exp_tnf(tetra_list, tri_nucl, di_nucl)\n",
    "    app_var = app_variance(expected_tnf, tetra_list, tri_nucl, di_nucl)\n",
    "    z_scores = tnf_z_score(tetra_freq, expected_tnf, app_var)\n",
    "    \n",
    "    return z_scores\n",
    "\n",
    "\n",
    "def inter_correlations(all_z_scores):\n",
    "    \"\"\"\n",
    "    Calcualte Person's correlation coefficient between fragment and median\n",
    "    \n",
    "    Input - np array of z-scores for all fragments\n",
    "    \n",
    "    Output - np array of correlation coeeficients\n",
    "    \"\"\"\n",
    "    \n",
    "    median_z = np.median(all_z_scores, axis=0)\n",
    "\n",
    "    correlations = np.zeros(len(all_z_scores))\n",
    "    for i in range(len(all_z_scores)):\n",
    "        correlations[i] = np.corrcoef(all_z_scores[i], median_z)[1,0]\n",
    "        \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def split_fragment(sequence, n):\n",
    "    \"\"\"\n",
    "    Split sequence into fragments no longer than n\n",
    "    \n",
    "    Inputs:\n",
    "    sequence - sequence\n",
    "    n - max length of fragment\n",
    "    \n",
    "    Output - fragments\n",
    "    \"\"\"\n",
    "    for i in range(0, len(sequence), n):\n",
    "        yield sequence[i:i + n]\n",
    "        \n",
    "def opt_len(s,l):\n",
    "    return math.ceil(len(s)/round(len(s)/l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tetranucleotide Z-scores for bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 characters other than A T C G found\n"
     ]
    }
   ],
   "source": [
    "contigs = SeqIO.parse(\"./test/bin.5.fa\", 'fasta')\n",
    "di_list, tri_list, tetra_list = nucl_lists()\n",
    "\n",
    "leng =[]\n",
    "contigs_z_scores = []\n",
    "for record in contigs:  \n",
    "    if len(record.seq) > 2500:\n",
    "        for fragment in split_fragment(record.seq, opt_len(record.seq, 5000)):\n",
    "            leng.append(len(fragment))\n",
    "            z_scores = get_z_scores(fragment, di_list, tri_list, tetra_list)\n",
    "            contigs_z_scores.append(z_scores)\n",
    "    \n",
    "contigs_z_scores = np.array(contigs_z_scores)\n",
    "contig_corr = inter_correlations(contigs_z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5a96595e943e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontig_corr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.distplot(contig_corr, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./contamination/s_marcescens/contaminated_0.05\n",
      "./contamination/s_marcescens/contaminated_0.4\n",
      "./contamination/s_marcescens/contaminated_0.15\n",
      "./contamination/s_marcescens/contaminated_0.35\n",
      "./contamination/s_marcescens/contaminated_0.3\n",
      "./contamination/s_marcescens/contaminated_0.25\n",
      "./contamination/s_marcescens/contaminated_0.1\n",
      "./contamination/s_marcescens/contaminated_0.2\n"
     ]
    }
   ],
   "source": [
    "bins_path = \"./contamination/s_marcescens/\"\n",
    "di_list, tri_list, tetra_list = nucl_lists()\n",
    "\n",
    "all_z = []\n",
    "all_corr = []\n",
    "names = []\n",
    "\n",
    "for fasta in os.listdir(bins_path):\n",
    "    \n",
    "    path = bins_path+fasta\n",
    "    print(path)\n",
    "    names.append(fasta)\n",
    "    \n",
    "    contigs = SeqIO.parse(path, 'fasta')\n",
    "    di_list, tri_list, tetra_list = nucl_lists()\n",
    "\n",
    "    contigs_z_scores = []\n",
    "    for record in contigs:  \n",
    "        if len(record.seq) > 2500:\n",
    "            for fragment in split_fragment(record.seq, opt_len(record.seq, 5000)):\n",
    "                z_scores = get_z_scores(fragment, di_list, tri_list, tetra_list)\n",
    "                contigs_z_scores.append(z_scores)\n",
    "\n",
    "    contigs_z_scores = np.array(contigs_z_scores)\n",
    "    contig_corr = inter_correlations(contigs_z_scores)\n",
    "    \n",
    "    all_z.append(contigs_z_scores)\n",
    "    all_corr.append(contig_corr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make easy to handle dataframes and save them for later \n",
    "frames = []\n",
    "for i in range(len(all_z)):\n",
    "    df = pd.DataFrame(all_z[i])\n",
    "    df['contamination'] = names[i].split('_')[1]\n",
    "    #df['genome'] = names[i]\n",
    "    frames.append(df)\n",
    "\n",
    "z = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "z.to_csv(\"s_marcescens_z.csv\",header=True, index=False)\n",
    "\n",
    "\n",
    "#Make Dataframe of correlations and save it for later\n",
    "vec = []\n",
    "for i in range(len(all_corr)):\n",
    "    for j in all_corr[i]:\n",
    "        vec.append(np.array([j,names[i].split('_')[1]]))\n",
    "        #vec.append(np.array([j,names[i]]))\n",
    "corr = pd.DataFrame(vec, columns=['corr', 'contamination'])\n",
    "\n",
    "corr.to_csv(\"s_marcescens_corr.csv\",header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw TN counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./contamination/s_marcescens/contaminated_0.05\n",
      "./contamination/s_marcescens/contaminated_0.4\n",
      "./contamination/s_marcescens/contaminated_0.15\n",
      "./contamination/s_marcescens/contaminated_0.35\n",
      "./contamination/s_marcescens/contaminated_0.3\n",
      "./contamination/s_marcescens/contaminated_0.25\n",
      "./contamination/s_marcescens/contaminated_0\n",
      "./contamination/s_marcescens/contaminated_0.1\n",
      "./contamination/s_marcescens/contaminated_0.2\n"
     ]
    }
   ],
   "source": [
    "bins_path = \"./contamination/s_marcescens/\"\n",
    "di_list, tri_list, tetra_list = nucl_lists()\n",
    "\n",
    "\n",
    "tnf_list = []\n",
    "names = []\n",
    "\n",
    "for fasta in os.listdir(bins_path):\n",
    "    \n",
    "    path = bins_path+fasta\n",
    "    print(path)\n",
    "    names.append(fasta)\n",
    "    \n",
    "    contigs = SeqIO.parse(path, 'fasta')\n",
    "    di_list, tri_list, tetra_list = nucl_lists()\n",
    "\n",
    "    contigs_tnf = []\n",
    "    for record in contigs:  \n",
    "        if len(record.seq) > 2500:\n",
    "            for fragment in split_fragment(record.seq, opt_len(record.seq, 5000)):\n",
    "                tnf = get_frequencies(fragment)\n",
    "                tnf = rev_comp_freq(tetra_list, tnf)\n",
    "                contigs_tnf.append(tnf)\n",
    "    \n",
    "    tnf_list.append(contigs_tnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in range(len(tnf_list)):\n",
    "    df = pd.DataFrame(tnf_list[i])\n",
    "    df['contamination'] = names[i].split('_')[1]\n",
    "    #df['genome'] = names[i]\n",
    "    frames.append(df)\n",
    "\n",
    "z = pd.concat(frames,ignore_index=True)\n",
    "\n",
    "z.to_csv(\"s_marcescens_counts.csv\",header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
